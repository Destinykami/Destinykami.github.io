---
title: '南京大学 PA3-批处理系统'
date: 2024/02/05
permalink: /posts/2024/01/nju-pa-3-1
excerpt: '南京大学 计算机基础PA3 批处理系统，用户程序和用户调用'
tags:
  - OS
---

有了强大的硬件保护机制, 用户程序将无法把执行流切换到操作系统的任意代码了. 但为了实现最简单的操作系统, 硬件还需要提供一种可以限制入口的执行流切换方式. 这种方式就是自陷指令, 程序执行自陷指令之后, 就会陷入到操作系统预先设置好的跳转目标. 这个跳转目标也称为异常入口地址.

这一过程是ISA规范的一部分, 称为中断/异常响应机制。  
## riscv32
riscv32提供ecall指令作为自陷指令, 并提供一个mtvec寄存器来存放异常入口地址. 为了保存程序当前的状态, riscv32提供了一些特殊的系统寄存器, 叫控制状态寄存器(CSR寄存器). 在PA中, 我们只使用如下3个CSR寄存器:

* mepc寄存器 - 存放触发异常的PC
* mstatus寄存器 - 存放处理器的状态
* mcause寄存器 - 存放触发异常的原因
riscv32触发异常后硬件的响应过程如下:  

1. 将当前PC值保存到mepc寄存器
2. 在mcause寄存器中设置异常号
3. 从mtvec寄存器中取出异常入口地址
4. 跳转到异常入口地址

需要注意的是, 上述保存程序状态以及跳转到异常入口地址的工作, 都是硬件自动完成的, 不需要程序员编写指令来完成相应的内容.  

由于异常入口地址是硬件和操作系统约定好的, 接下来的处理过程将会由操作系统来接管, 操作系统将视情况决定是否终止当前程序的运行(例如触发段错误的程序将会被杀死). 若决定无需杀死当前程序, 等到异常处理结束之后, 就根据之前保存的信息恢复程序的状态, 并从异常处理过程中返回到程序触发异常之前的状态. 具体地:

* x86通过iret指令从异常处理过程中返回, 它将栈顶的三个元素来依次解释成eip, cs, eflags, 并恢复它们.
* mips32通过eret指令从异常处理过程中返回, 它将清除status寄存器中的异常标志, 并根据epc寄存器恢复PC.
* riscv32通过mret指令从异常处理过程中返回, 它将根据mepc寄存器恢复PC.
**这即是在接下来要完善的mret指令所要做的事**

## 状态机视角下的异常响应机制
程序是个$S = <R, M>$的状态机, 我们之前已经讨论过在TRM和IOE中这个状态机的具体行为. 如果要给计算机添加异常响应机制, 我们又应该如何对这个状态机进行扩充呢?

首先当然是对R的扩充, 除了PC和通用寄存器之外, 还需要添加上文提到的一些特殊寄存器. 我们不妨把这些寄存器称为系统寄存器(System Register), 因为这些寄存器的作用都是和系统功能相关的, 平时进行计算的时候不会使用. 扩充之后的寄存器可以表示为R = {GPR, PC, SR}. 异常响应机制和内存无关, 因此我们无需对M的含义进行修改.

对状态转移的扩充就比较有趣了. 我们之前都是认为程序执行的每一条指令都会成功, 从而状态机会根据指令的语义进行状态转移. 添加异常响应机制之后, 我们允许一条指令的执行会"失败". 为了描述指令执行失败的行为, 我们可以假设CPU有一条虚构的指令`raise_intr`, 执行这条虚构指令的行为就是上文提到的异常响应过程. 显然, 这一行为是可以用状态机视角来描述的, 例如在riscv32中可以表示成:
```
SR[mepc] <- PC
SR[mcause] <- 一个描述失败原因的号码
PC <- SR[mtvec]
```
有了这条虚构的指令, 我们就可以从状态机视角来理解异常响应的行为了: 如果一条指令执行成功, 其行为和之前介绍的TRM与IOE相同; 如果一条指令执行失败, 其行为等价于执行了虚构的raise_intr指令.

# 将上下文管理抽象成CTE
我们刚才提到了程序的状态, 在操作系统中有一个等价的术语, 叫"上下文". 因此, 硬件提供的上述在操作系统和用户程序之间切换执行流的功能, 在操作系统看来, 都可以划入上下文管理的一部分.

与IOE一样, 上下文管理的具体实现也是架构相关的: 例如上文提到, x86/mips32/riscv32中分别通过int/syscall/ecall指令来进行自陷, native中甚至可以通过一些神奇的库函数来模拟相应的功能; 而上下文的具体内容, 在不同的架构上也显然不一样(比如寄存器就已经不一样了). 于是, 我们可以将上下文管理的功能划入到AM的一类新的API中, 名字叫CTE(ConText Extension).  

接下来的问题是, 如何将不同架构的上下文管理功能抽象成统一的API呢? 换句话说, 我们需要思考, 操作系统的处理过程其实需要哪些信息?

* 首先当然是**引发这次执行流切换的原因**, 是程序除0, 非法指令, 还是触发断点, 又或者是程序自愿陷入操作系统? 根据不同的原因, 操作系统都会进行不同的处理.
* 然后就是**程序的上下文**了, 在处理过程中, 操作系统可能会读出上下文中的一些寄存器, 根据它们的信息来进行进一步的处理. 例如操作系统读出PC所指向的非法指令, 看看其是否能被模拟执行. 事实上, 通过这些上下文, 操作系统还能实现一些神奇的功能, 你将会在PA4中了解更详细的信息.

所以, 我们只要把这两点信息抽象成一种统一的表示方式, 就可以定义出CTE的API了. 对于切换原因, 我们只需要定义一种统一的描述方式即可. CTE定义了名为"事件"的如下数据结构(见abstract-machine/am/include/am.h):
```c
typedef struct Event {
  enum { ... } event;
  uintptr_t cause, ref;
  const char *msg;
} Event;
```
其中`event`表示事件编号, `cause`和`ref`是一些描述事件的补充信息, msg是事件信息字符串, 我们在PA中只会用到`event`. 然后, 我们只要定义一些统一的事件编号(上述枚举常量), 让每个架构在实现各自的CTE API时, 都统一通过上述结构体来描述执行流切换的原因, 就可以实现切换原因的抽象了.

对于上下文, 我们只能将描述上下文的结构体类型名统一成Context, 至于其中的具体内容, 就无法进一步进行抽象了. 这主要是因为不同架构之间上下文信息的差异过大, 比如mips32有32个通用寄存器, 就从这一点来看, mips32和x86的Context注定是无法抽象成完全统一的结构的. 

最后还有另外两个统一的API:

* `bool cte_init(Context* (*handler)(Event ev, Context *ctx))`用于进行CTE相关的初始化操作. 其中它还接受一个来自操作系统的事件处理回调函数的指针, 当发生事件时, CTE将会把事件和相关的上下文作为参数, 来调用这个回调函数, 交由操作系统进行后续处理.
* `void yield()`用于进行自陷操作, 会触发一个编号为EVENT_YIELD事件. 不同的ISA会使用不同的自陷指令来触发自陷操作, 具体实现请RTFSC.

## 设置异常入口地址
在触发自陷操作前, 首先需要按照ISA的约定来设置异常入口地址, 将来切换执行流时才能跳转到正确的异常入口. 这显然是架构相关的行为, 因此我们把这一行为放入CTE中, 而不是让am-tests直接来设置异常入口地址. 当我们选择`yield test`时, `am-tests`会通过`cte_init()`函数对CTE进行初始化, 其中包含一些简单的宏展开代码. 这最终会调用位于`abstract-machine/am/src/$ISA/nemu/cte.c`中的`cte_init()`函数. `cte_init()`函数会做两件事情:
* 设置异常入口地址:

  * 对x86来说, 就是要准备一个有意义的IDT  
代码定义了一个结构体数组idt, 它的每一个元素是一个门描述符结构体
在相应的数组元素中填写有意义的门描述符, 例如编号为0x81的门描述符中就包含自陷操作的入口地址. 需要注意的是, 框架代码中还是填写了完整的门描述符(包括上文中提到的don't care的域), 这主要是为了进行DiffTest时让KVM也能跳转到正确的入口地址. KVM实现了完整的x86异常响应机制, 如果只填写简化版的门描述符, 代码就无法在其中正确运行. 但我们无需了解其中的细节, 只需要知道代码已经填写了正确的门描述符即可.  
通过lidt指令在IDTR中设置idt的首地址和长度

  * 对于mips32来说, 由于异常入口地址是固定在0x80000180, 因此我们需要在0x80000180放置一条无条件跳转指令, 使得这一指令的跳转目标是我们希望的真正的异常入口地址即可.
  * 对于riscv32来说, 直接将异常入口地址设置到mtvec寄存器中即可.

* 注册一个事件处理回调函数, 这个回调函数由yield test提供

## 触发自陷操作
为了支撑自陷操作, 同时测试异常入口地址是否已经设置正确, 需要在NEMU中实现isa_raise_intr()函数 (在nemu/src/isa/$ISA/system/intr.c中定义)来模拟上文提到的异常响应机制.  
进行寄存器值的变更  
但是这个寄存器需要自己去定义  
```c
word_t isa_raise_intr(word_t NO, vaddr_t epc) {
  /* TODO: Trigger an interrupt/exception with ``NO''.
   * Then return the address of the interrupt/exception vector.
   */
  cpu.csr.mcause=NO;
  cpu.csr.mepc=epc;
  return cpu.csr.mtvec;
}
```
```c
//isa-def.h
typedef struct {
  word_t mcause;
  vaddr_t mepc;
  word_t mstatus;
  word_t mtvec;
} riscv32_CSRs;
 
typedef struct {
  word_t gpr[32];
  vaddr_t pc;
  riscv32_CSRs csr;
} riscv32_CPU_state;
```
## 保存上下文
成功跳转到异常入口地址之后, 我们就要在软件上开始真正的异常处理过程了. 但是, 进行异常处理的时候不可避免地需要用到通用寄存器, 然而看看现在的通用寄存器, 里面存放的都是执行流切换之前的内容. 这些内容也是上下文的一部分, 如果不保存就覆盖它们, 将来就无法恢复这一上下文了. 但通常硬件并不负责保存它们, 因此需要通过软件代码来保存它们的值. x86提供了pusha指令, 用于把通用寄存器的值压栈; 而mips32和riscv32则通过sw指令将各个通用寄存器依次压栈.

除了通用寄存器之外, 上下文还包括:

* 触发异常时的PC和处理器状态. 对于x86来说就是eflags, cs和eip, x86的异常响应机制已经将它们保存在堆栈上了; 对于mips32和riscv32来说, 就是epc/mepc和status/mstatus寄存器, 异常响应机制把它们保存在相应的系统寄存器中, 我们还需要将它们从系统寄存器中读出, 然后保存在堆栈上.
* 异常号. 对于x86, 异常号由软件保存; 而对于mips32和riscv32, 异常号已经由硬件保存在cause/mcause寄存器中, 我们还需要将其保存在堆栈上.
* 地址空间. 这是为PA4准备的, 在x86中对应的是CR3寄存器, 代码通过一条pushl $0指令在堆栈上占位, mips32和riscv32则是将地址空间信息与0号寄存器共用存储空间, 反正0号寄存器的值总是0, 也不需要保存和恢复. 不过目前我们暂时不使用地址空间信息, 你目前可以忽略它们的含义.

> 异常号的保存  
x86通过软件来保存异常号, 没有类似cause的寄存器. mips32和riscv32也可以这样吗? 为什么?  
TODO

于是, 这些内容构成了完整的上下文信息, 异常处理过程可以根据上下文来诊断并进行处理, 同时, 将来恢复上下文的时候也需要这些信息.

### 重新组织Context结构体
你的任务如下:

实现这一过程中的新指令, 详情请RTFM.  
理解上下文形成的过程并RTFSC, 然后重新组织`abstract-machine/am/include/arch/$ISA-nemu.h` 中定义的Context结构体的成员, 使得这些成员的定义顺序和 `abstract-machine/am/src/$ISA/nemu/trap.S`中构造的上下文保持一致.  
需要注意的是, 虽然我们目前暂时不使用上文提到的地址空间信息, 但你在重新组织Context结构体时仍然需要正确地处理地址空间信息的位置, 否则你可能会在PA4中遇到难以理解的错误.  

实现之后, 你可以在`__am_irq_handle()`中通过printf输出上下文c的内容, 然后通过简易调试器观察触发自陷时的寄存器状态, 从而检查你的Context实现是否正确.

```
trap.S:

  MAP(REGS, PUSH)

  csrr t0, mcause
  csrr t1, mstatus
  csrr t2, mepc

  STORE t0, OFFSET_CAUSE(sp)
  STORE t1, OFFSET_STATUS(sp)
  STORE t2, OFFSET_EPC(sp)
```
于是**猜测**顺序应该是 :
```
struct Context {
  // TODO: fix the order of these members to match trap.S
  uintptr_t gpr[32];
  uintptr_t mcause, mstatus, mepc;
  void *pdir;
};
```

## 事件分发
`__am_irq_handle()`的代码会把执行流切换的原因打包成事件, 然后调用在`cte_init()`中注册的事件处理回调函数, 将事件交给`yield test`来处理. 在`yield test`中, 这一回调函数是`am-kernels/tests/am-tests/src/tests/intr.c`中的`simple_trap()`函数. `simple_trap()`函数会根据事件类型再次进行分发. 不过我们在这里会触发一个未处理的事件:

`AM Panic: Unhandled event @ am-kernels/tests/am-tests/src/tests/intr.c:12`  
这是因为CTE的`__am_irq_handle()`函数并未正确识别出自陷事件. 根据`yield()`的定义, `__am_irq_handle()`函数需要将自陷事件打包成编号为`EVENT_YIELD`的事件.

### 识别自陷事件
你需要在`__am_irq_handle()`中通过异常号识别出自陷异常, 并打包成编号为`EVENT_YIELD`的自陷事件. 重新运行`yield test`, 如果你的实现正确, 你会看到识别到自陷事件之后输出一个字符y.
```c
Context* __am_irq_handle(Context *c) {
  if (user_handler) {
    Event ev = {0};
    switch (c->mcause) {
      case EVENT_YIELD: ev.event = EVENT_YIELD; break; //新增
      default: ev.event = EVENT_ERROR; break;
    }

    c = user_handler(ev, c);
    assert(c != NULL);
  }

  return c;
}
```
此外还需要完成几条PA2中没有涉及到的指令：
```c
#define EVENT_YIELD 1
#define EVENT_SYSCALL 2
#define ECALL(dnpc)                                                  \
  {                                                                  \
    bool success;                                                    \
    int tmp=isa_reg_str2val("a7", &success);\
    if(tmp==-1) dnpc = (isa_raise_intr(EVENT_YIELD, s->pc));\
    else dnpc = (isa_raise_intr(EVENT_SYSCALL, s->pc));\
  } 
//系统调用是通过自陷指令来实现的，因此要根据a7寄存器来区分是普通自陷还是系统调用
#define CSR(i) *csr_register(i)
static vaddr_t MRET(){
  return cpu.csr.mepc+4;
}
static vaddr_t *csr_register(word_t imm) {
  switch (imm)
  {
    //地址是查阅文档得到的
    case 0x341: return &(cpu.csr.mepc);
    case 0x342: return &(cpu.csr.mcause);
    case 0x300: return &(cpu.csr.mstatus);
    case 0x305: return &(cpu.csr.mtvec);
    default: panic("Unknown csr");
  }
}
  //pa3新增
  INSTPAT("??????? ????? ????? 001 ????? 11100 11", csrrw  , I, R(rd) = CSR(imm); CSR(imm) = src1);
  INSTPAT("??????? ????? ????? 010 ????? 11100 11", csrrs  , I, R(rd) = CSR(imm); CSR(imm) |= src1);
  INSTPAT("0000000 00000 00000 000 00000 11100 11", ecall  , I, ECALL(s->dnpc));
  INSTPAT("0011000 00010 00000 000 00000 11100 11", mret, I, s->dnpc=MRET());
```

## 恢复上下文
代码将会一路返回到`trap.S`的`__am_asm_trap()`中, 接下来的事情就是恢复程序的上下文. `__am_asm_trap()`将根据之前保存的上下文内容, 恢复程序的状态, 最后执行"异常返回指令"返回到程序触发异常之前的状态.

不过这里需要注意之前自陷指令保存的PC, 对于x86的int指令, 保存的是指向其下一条指令的PC, 这有点像函数调用; 而对于`mips32`的`syscall`和`riscv32`的`ecall`, 保存的是自陷指令的PC, 因此软件需要在适当的地方对保存的PC加上4, 使得将来返回到自陷指令的下一条指令.

代码最后会返回到`yield test`触发自陷的代码位置, 然后继续执行. 在它看来, 这次时空之旅就好像没有发生过一样.

>你需要实现这一过程中的新指令. 重新运行`yield test`. 如果你的实现正确, `yield test`将不断输出y.

在mret指令的返回值中已经实现了。
```c
static vaddr_t MRET(){
  return cpu.csr.mepc+4;
}
```
![PA3.1](/images/PA/PA3.1.png)

## 用户程序和系统调用
### 加载第一个用户程序
在操作系统中, 加载用户程序是由loader(加载器)模块负责的. 我们知道程序中包括代码和数据, 它们都是存储在可执行文件中. 加载的过程就是把可执行文件中的代码和数据放置在正确的内存位置, 然后跳转到程序入口, 程序就开始执行了. 更具体的, 为了实现loader()函数, 我们需要解决以下问题:

* 可执行文件在哪里?
* 代码和数据在可执行文件的哪个位置?
* 代码和数据有多少?
* "正确的内存位置"在哪里?

### ELF文件
ELF文件提供了两个视角来组织一个可执行文件, 一个是面向链接过程的section视角, 这个视角提供了用于链接与重定位的信息(例如符号表); 另一个是面向执行的segment视角, 这个视角提供了用于加载可执行文件的信息. 通过readelf命令, 我们还可以看到section和segment之间的映射关系: 一个segment可能由0个或多个section组成, 但一个section可能不被包含于任何segment中.

我们现在关心的是如何加载程序, 因此我们重点关注segment的视角. ELF中采用program header table来管理segment, program header table的一个表项描述了一个segment的所有属性, 包括类型, 虚拟地址, 标志, 对齐方式, 以及文件内偏移量和segment大小. 根据这些信息, 我们就可以知道需要加载可执行文件的哪些字节了, 同时我们也可以看到, 加载一个可执行文件并不是加载它所包含的所有内容, 只要加载那些与运行时刻相关的内容就可以了, 例如调试信息和符号表就不必加载. 我们可以通过判断segment的Type属性是否为PT_LOAD来判断一个segment是否需要加载.  

需要找出每一个需要加载的segment的Offset, VirtAddr, FileSiz和MemSiz这些参数. 其中相对文件偏移Offset指出相应segment的内容从ELF文件的第Offset字节开始, 在文件中的大小为FileSiz, 它需要被分配到以VirtAddr为首地址的虚拟内存位置, 在内存中它占用大小为MemSiz. 也就是说, 这个segment使用的内存就是[VirtAddr, VirtAddr + MemSiz)这一连续区间, 然后将segment的内容从ELF文件中读入到这一内存区间, 并将[VirtAddr + FileSiz, VirtAddr + MemSiz)对应的物理区间清零.  

事实上, loader的工作向我们展现出了程序的最为原始的状态: 比特串! 加载程序其实就是把这一毫不起眼的比特串放置在正确的位置, 但这其中又折射出"存储程序"的划时代思想: 当操作系统将控制权交给它的时候, 计算机把它解释成指令并逐条执行. loader让计算机的生命周期突破程序的边界: 一个程序结束并不意味着计算机停止工作, 计算机将终其一生履行执行程序的使命.

>实现loader  
你需要在Nanos-lite中实现loader的功能, 来把用户程序加载到正确的内存位置, 然后执行用户程序. loader()函数在nanos-lite/src/loader.c中定义, 其中的pcb参数目前暂不使用, 可以忽略, 而因为ramdisk中目前只有一个文件, filename参数也可以忽略. 在下一个阶段实现文件系统之后, filename就派上用场了.  
ELF文件的开头都有一个特殊的**魔数**, 为了防止loader加载了一个非ELF格式的文件, 我们可以在loader中对魔数进行检查
```c
static uintptr_t loader(PCB *pcb, const char *filename)
{
  // ELF文件的头部信息。
  Elf_Ehdr ehdr;
  // 使用ramdisk_read函数从ramdisk中读取ELF文件的头部信息，从偏移量0开始读取sizeof(Elf_Ehdr)字节的数据。
  ramdisk_read(&ehdr, 0, sizeof(Elf_Ehdr));
  // 用于检查ELF文件的合法性    0x7f454c46  由于是小端序，所以要逆序
   assert((*(uint32_t *)ehdr.e_ident == 0x464c457f)); 
  // 创建一个Elf_Phdr类型的数组phdr，用于存储ELF文件的程序头表信息。ehdr.e_phnum表示头部表的数量
  Elf_Phdr phdr[ehdr.e_phnum];
  // 使用ramdisk_read函数从ramdisk中读取程序头表信息。ehdr.e_ehsize指示了程序头表在文件中的偏移量，
  // sizeof(Elf_Phdr)*ehdr.e_phnum表示要读取的字节数，将所有程序头表都读取到数组phdr中。
  ramdisk_read(phdr, ehdr.e_ehsize, sizeof(Elf_Phdr) * ehdr.e_phnum);
  for (size_t i = 0; i < ehdr.e_phnum; i++)
  {
    // 检查当前程序头表条目的类型是否为PT_LOAD，表示这是一个需要加载到内存中的段
    if (phdr[i].p_type == PT_LOAD)
    {
      // 使用ramdisk_read函数将当前段的内容从ramdisk中读取到内存中。phdr[i].p_vaddr表示段的虚拟地址，
      // phdr[i].p_offset表示段在文件中的偏移量，phdr[i].p_memsz表示段在内存中的大小。
      ramdisk_read((void *)phdr[i].p_vaddr, phdr[i].p_offset, phdr[i].p_memsz);
      // 如果段的文件大小小于内存大小，这个代码用于将未初始化部分（即.bss部分）填充为零。
      memset((void *)(phdr[i].p_vaddr + phdr[i].p_filesz), 0, phdr[i].p_memsz - phdr[i].p_filesz);
    }
  }
  // 返回ELF文件的入口地址，表示加载并准备执行的程序的入口点。
  return ehdr.e_entry;
}
```

## 操作系统的运行时环境
程序的运行需要运行时环境的支撑. 而操作系统希望加载并运行程序, 自然有责任来提供运行时环境的功能.  
在PA2中, 我们的计算机系统是被一个程序独占的, 它可以想怎么玩就怎么玩, 玩坏了也是它一个程序的事情. 而在现代的计算机系统中, 可能会有多个程序并发甚至同时使用计算机系统中的资源. 如果每个程序都直接使用这些资源, 各自都不知道对方的使用情况, 很快整个系统就会乱套了: 比如我覆盖了你的画面, 你覆盖了我的内存空间...  
所以需要有一个角色来对系统中的资源进行统一的管理: 程序不能擅自使用资源了, 使用的时候需要向资源管理者提出申请. 既然操作系统位于高特权级, 享受着至高无上的权利, 自然地它也需要履行相应的义务: 作为资源管理者管理着系统中的所有资源, 操作系统还需要为用户程序提供相应的服务. 这些服务需要以一种统一的接口来呈现, 用户程序也只能通过这一接口来请求服务.

这一接口就是**系统调用**. 这是操作系统从诞生那一刻就被赋予的使命: 我们之前提到GM-NAA I/O的一个主要任务就是加载新程序, 而它的另一个主要功能, 就是为程序提供输入输出的公共接口. GM-NAA I/O所提供的公共接口, 可以认为是系统调用的初原形态.  

于是, 系统调用把整个运行时环境分成两部分, 一部分是操作系统内核区, 另一部分是用户区. 那些会访问系统资源的功能会放到内核区中实现, 而用户区则保留一些无需使用系统资源的功能(比如strcpy()), 以及用于请求系统资源相关服务的系统调用接口.

在这个模型之下, 用户程序只能在用户区安分守己地"计算", 任何超越纯粹计算能力之外的任务, 都需要通过系统调用向操作系统请求服务. 如果用户程序尝试进行任何非法操作, CPU就会向操作系统抛出一个异常信号, 让非法操作的指令执行"失败", 并交由操作系统进行处理. 

虽然操作系统需要为用户程序服务, 但这并不意味着操作系统需要把所有信息都暴露给用户程序. 有些信息是用户进程没有必要知道的, 也永远不应该知道, 例如一些与内存管理相关的数据结构. 如果一个恶意程序获得了这些信息, 可能会为恶意攻击提供了信息基础. 因此, 通常不存在一个系统调用来获取这些操作系统的私有数据.

## 系统调用
用户程序执行系统调用的时候也是类似的情况, 要通过一种方法描述自己的需求, 然后告诉操作系统.在GNU/Linux中, 用户程序通过自陷指令来触发系统调用, Nanos-lite也沿用这个约定. CTE中的`yield()`也是通过自陷指令来实现, 虽然它们触发了不同的事件, 但从上下文保存到事件分发, 它们的过程都是非常相似的. 既然我们通过自陷指令来触发系统调用, 那么对用户程序来说, 用来向操作系统描述需求的最方便手段就是使用通用寄存器了, 因为执行自陷指令之后, 执行流就会马上切换到事先设置好的入口, 通用寄存器也会作为上下文的一部分被保存起来. 系统调用处理函数只需要从上下文中获取必要的信息, 就能知道用户程序发出的服务请求是什么了.

Navy已经为用户程序准备好了系统调用的接口了. navy-apps/libs/libos/src/syscall.c中定义的`_syscall_()`函数已经蕴含着上述过程:
```c
intptr_t _syscall_(intptr_t type, intptr_t a0, intptr_t a1, intptr_t a2) {
  // ...
  asm volatile (SYSCALL : "=r" (ret) : "r"(_gpr1), "r"(_gpr2), "r"(_gpr3), "r"(_gpr4));
  return ret;
}
```
上述代码会先把系统调用的参数依次放入寄存器中, 然后执行自陷指令. 由于寄存器和自陷指令都是ISA相关的, 因此这里根据不同的ISA定义了不同的宏, 来对它们进行抽象. CTE会将这个自陷操作打包成一个系统调用事件EVENT_SYSCALL, 并交由Nanos-lite继续处理.

> 识别系统调用  
目前dummy已经通过`_syscall_()`直接触发系统调用, 你需要让Nanos-lite识别出系统调用事件`EVENT_SYSCALL.`  
处理器通常只会提供一条自陷指令, 这时EVENT_SYSCALL和EVENT_YIELD 都通过相同的自陷指令来实现, 因此CTE需要额外的方式区分它们. 如果自陷指令本身可以携带参数, 就可以用不同的参数指示不同的事件, 例如x86和mips32都可以采用这种方式; 如果自陷指令本身不能携带参数, 那就需要通过其他状态来区分, 一种方式是通过某个寄存器的值来区分, riscv32采用这种方式.  
**通过a7寄存器来判断**  

Nanos-lite收到系统调用事件之后, 就会调出系统调用处理函数do_syscall()进行处理. do_syscall()首先通过宏GPR1从上下文c中获取用户进程之前设置好的系统调用参数, 通过第一个参数 - 系统调用号 - 进行分发.  

添加一个系统调用比你想象中要简单, 所有信息都已经准备好了. 我们只需要在分发的过程中添加相应的系统调用号, 并编写相应的系统调用处理函数sys_xxx(), 然后调用它即可. 回过头来看dummy程序, 它触发了一个SYS_yield系统调用. 我们约定, 这个系统调用直接调用CTE的yield()即可, 然后返回0.

处理系统调用的最后一件事就是设置系统调用的返回值. 对于不同的ISA, 系统调用的返回值存放在不同的寄存器中, 宏GPRx用于实现这一抽象, 所以我们通过GPRx来进行设置系统调用返回值即可.

经过CTE, 执行流会从do_syscall()一路返回到用户程序的_syscall_()函数中. 代码最后会从相应寄存器中取出系统调用的返回值, 并返回给_syscall_()的调用者, 告知其系统调用执行的情况(如是否成功等).

>  实现SYS_yield系统调用   
  1. 在abstract-machine/am/include/arch/目录下的相应头文件中实现正确的GPR?宏, 让它们从上下文c中获得正确的系统调用参数寄存器.
  2. 添加SYS_yield系统调用.
  3. 设置系统调用的返回值.  

> 实现SYS_exit系统调用  
 它会接收一个退出状态的参数. 为了方便测试, 我们目前先直接使用这个参数调用halt(). 实现成功后, 再次运行dummy程序, 你会看到HIT GOOD TRAP的信息.  

```c
//riscv.h
#define GPR1 gpr[17] // a7
#define GPR2 gpr[10]//a0
#define GPR3 gpr[11]//a1
#define GPR4 gpr[12]//a2
#define GPRx gpr[10]//a0

//syscall.c
#include <common.h>
#include "syscall.h"
int sys_yield();
void sys_exit(int status);
int sys_write(int fd, void *buf, size_t count);

void do_syscall(Context *c) {
  uintptr_t a[4];
  a[0] = c->GPR1;
  intptr_t ret;
  switch (a[0]) {
    case SYS_yield: ret = sys_yield(); break;
    case SYS_exit: sys_exit(c->GPR2); break;
    case SYS_write:
        ret = sys_write(c->GPR2, (void *)c->GPR3, (size_t)c->GPR4);
        //Log("sys_write(%d, %p, %d) = %d", c->GPR2, c->GPR3, c->GPR4, ret);
        break;
    default: panic("Unhandled syscall ID = %d", a[0]);
  }

  c->GPRx = ret; //  gpr[10]为syscall的返回值
}
int sys_yield(){
  yield();
  printf("sys_yield\n");
  return 0;
}
void sys_exit(int status) {
  printf("sys_exit\n");
  halt(status);
}
```
## 操作系统之上的TRM
### 标准输出
在GNU/Linux中, 输出是通过SYS_write系统调用来实现的. 根据write的函数声明(参考man 2 write), 你需要在do_syscall()中识别出系统调用号是SYS_write之后, 检查fd的值, 如果fd是1或2(分别代表stdout和stderr), 则将buf为首地址的len字节输出到串口(使用putch()即可). 最后还要设置正确的返回值, 否则系统调用的调用者会认为write没有成功执行, 从而进行重试.另外不要忘记在navy-apps/libs/libos/src/syscall.c的_write()中调用系统调用接口函数.
```c
//nanos-lite/src/syscall.c
int sys_write(int fd, void *buf, size_t count) {
    if (fd == 1 || fd == 2) {
        for (size_t i = 0; i < count; ++i) {
            putch(*((char *)buf + i));
        }
        return count;
    }
    return -1;
}
//navy-apps/libs/libos/src/syscall.c
int _write(int fd, void *buf, size_t count) {
  //_exit(SYS_write);
  //return 0;
  return _syscall_(SYS_write, fd, (intptr_t)buf, count);
}

```
> 在Nanos-lite上运行Hello world  
Navy中提供了一个hello测试程序(navy-apps/tests/hello), 它首先通过write()来输出一句话, 然后通过printf()来不断输出.  
你需要实现write()系统调用, 然后把Nanos-lite上运行的用户程序切换成hello程序来运行.  
切换程序和dummy一样，在navyapp中编译后，将img文件手动复制过去加载运行。  
![PA3.2](/images/PA/PA3.2.png)

### 堆区管理
调整堆区大小是通过sbrk()库函数来实现的.

它的原型是
```c
void* sbrk(intptr_t increment);
```

用于将用户程序的program break增长increment字节, 其中increment可为负数. 所谓program break, 就是用户程序的数据段(data segment)结束的位置. 我们知道可执行文件里面有代码段和数据段, 链接的时候ld会默认添加一个名为_end的符号, 来指示程序的数据段结束的位置. 用户程序开始运行的时候, program break会位于_end所指示的位置, 意味着此时堆区的大小为0. malloc()被第一次调用的时候, 会通过sbrk(0)来查询用户程序当前program break的位置, 之后就可以通过后续的sbrk()调用来动态调整用户程序program break的位置了. 当前program break和和其初始值之间的区间就可以作为用户程序的堆区, 由malloc()/free()进行管理. 注意用户程序不应该直接使用sbrk(), 否则将会扰乱malloc()/free()对堆区的管理记录.

在Navy的Newlib中, sbrk()最终会调用_sbrk(), 它在navy-apps/libs/libos/src/syscall.c中定义. 框架代码让_sbrk()总是返回-1, 表示堆区调整失败, 事实上, 用户程序在第一次调用printf()的时候会尝试通过malloc()申请一片缓冲区, 来存放格式化的内容. 若申请失败, 就会逐个字符进行输出. 如果你在Nanos-lite中打开strace, 你会发现用户程序通过printf()输出的时候, 确实是逐个字符地调用write()来输出的.

但如果堆区总是不可用, Newlib中很多库函数的功能将无法使用, 因此现在你需要实现_sbrk()了. 为了实现_sbrk()的功能, 我们还需要提供一个用于设置堆区大小的系统调用. 在GNU/Linux中, 这个系统调用是SYS_brk, 它接收一个参数addr, 用于指示新的program break的位置. _sbrk()通过记录的方式来对用户程序的program break位置进行管理, 其工作方式如下:

1. program break一开始的位置位于_end
2. 被调用时, 根据记录的program break位置和参数increment, 计算出新program break
3. 通过SYS_brk系统调用来让操作系统设置新program break
4. 若SYS_brk系统调用成功, 该系统调用会返回0, 此时更新之前记录的program break的位置, 并将旧program break的位置作为_sbrk()的返回值返回
5. 若该系统调用失败, _sbrk()会返回-1

上述代码是在用户层的库函数中实现的, 我们还需要在Nanos-lite中实现SYS_brk的功能. 由于目前Nanos-lite还是一个单任务操作系统, 空闲的内存都可以让用户程序自由使用, 因此我们只需要让SYS_brk系统调用总是返回0即可, 表示堆区大小的调整总是成功. 在PA4中, 我们会对这一系统调用进行修改, 实现真正的内存分配.
```c
extern int _end;
int program_break = (int)(&_end);
void *_sbrk(intptr_t increment) {
  int program_break_prev = program_break;
  if (_syscall_(SYS_brk, program_break + increment, 0, 0) == 0) {
      program_break = program_break + increment;
      return (void *)program_break_prev;
  }
  return (void *)-1;
}
```
![PA3.3](/images/PA/PA3.3.png)
